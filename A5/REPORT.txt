<-- Raw Data -->

N = 1, K = 1
+---------------------------------------------------------------------------+
| Num Clients |   Insert    |    Lookup     |    Scan       |    Remove     |
+---------------------------------------------------------------------------+
|      1      |    572.85   |    4186.17    |    597.78     |     538.52    |
-----------------------------------------------------------------------------
|      2      |    669.02   |    5561.58    |   1110.79     |     596.61    |
-----------------------------------------------------------------------------
|      3      |    637.98   |   12930.42    |   1118.12     |     668.19    |
-----------------------------------------------------------------------------
|      4      |    632.58   |   15726.88    |   1651.48     |     725.84    |
-----------------------------------------------------------------------------
|      5      |    693.75   |   16984.59    |   1905.81     |     723.56    |
-----------------------------------------------------------------------------
|      6      |    595.42   |   16645.12    |   2480.48     |     551.49    |
+---------------------------------------------------------------------------+

N = 3, K = 2
+---------------------------------------------------------------------------+
| Num Clients |   Insert    |    Lookup     |    Scan       |    Remove     |
+---------------------------------------------------------------------------+
|      1      |    263.08   |    3731.02    |    645.37     |     254.84    |
-----------------------------------------------------------------------------
|      2      |    515.00   |    8180.45    |   1402.85     |     602.39    |
-----------------------------------------------------------------------------
|      3      |    712.28   |   13061.55    |   1934.01     |     919.50    |
-----------------------------------------------------------------------------
|      4      |    791.76   |   17540.17    |   2181.29     |    1095.94    |
-----------------------------------------------------------------------------
|      5      |    865.75   |   21834.99    |   2175.45     |    1345.68    |
-----------------------------------------------------------------------------
|      6      |    823.17   |   24936.50    |   2478.88     |    1022.45    |
+---------------------------------------------------------------------------+

N = 5, K = 3
+---------------------------------------------------------------------------+
| Num Clients |   Insert    |    Lookup     |    Scan       |    Remove     |
+---------------------------------------------------------------------------+
|      1      |    167.85   |    3666.39    |    628.54     |     155.40    |
-----------------------------------------------------------------------------
|      2      |    337.58   |    8140.85    |   1336.90     |     634.29    |
-----------------------------------------------------------------------------
|      3      |    441.15   |   12677.70    |   2149.38     |    1005.41    |
-----------------------------------------------------------------------------
|      4      |    664.13   |   17105.82    |   2564.67     |    1109.22    |
-----------------------------------------------------------------------------
|      5      |    770.30   |   21673.55    |   2644.94     |    1512.72    |
-----------------------------------------------------------------------------
|      6      |    886.08   |   27031.25    |   2773.15     |    1213.47    |
-----------------------------------------------------------------------------
|      7      |    857.56   |   30791.33    |   3067.72     |    1394.34    |
+---------------------------------------------------------------------------+

First of all, I should note that my operations tend to fail and send back a bad 
request response quickly if a value is not found, which can inflate my throughput 
depending on the state of the hash table when each client is interacting with it,
especially as more and more clients are added. The actual output from each test
would be very long and so is instead summarized, but this inflated speed I am
referring to can be seen by the major inconsisitincies in the throughput for the
same operation on different clients. The larger the throughput is, the more early
failures there were, or in the case of scan, there were just less values in the
dictionary at that point.

I will assume because we already discussed the differences in throughputs between
the different operations before, we wont need to go into detail about why one
operation is faster than another in the context of a persistent system like we
showed in A3. The interesting thing to us here is how adding more concurrent
clients affects the systems performance, and then comparing several of those
systems with different levels of sharding and replication.

For the single server case (N = 1, K = 1), the data shows that insert does not 
improve in speed much as more concurrent clients are added, which is what we would 
expect because there is no concurrency server-side to speed this up, so each client 
just has to wait for the other anyway. This same thing is true for the remove 
operation as well. In terms of lookup and scan, both become faster as we add more 
clients, as the interleaving of requests allows for multiple to be handled at once.

For the N = 3, K = 2 case, we can seethat the throughput of all of our operations
improves as we add more clients. With only one client, compared to the N = 1
k = 1 case, this system is actually slower. This is to be expected becasue there
is replication happining, so more work is being done for each request. However,
as more clients are added we can see that the throughput of all ops quickly
overtakes that of the other system. This is expected because as concurrent
clients are added, the system can take advantage of the fact that multiple
servers are filling requests rather than being bottlenecked by the speed
of a single client. 

Scan recieves a quick performance boost from adding clients but quickly levels 
out due to the fact that replication is occurring and it must go through each 
value twice, or even more in the next case. Lookup recieves the largest benefit 
from having multiple servers because the first connection to find it will return 
the value, meaning that the system is taking full advantage of having multiple 
clients and servers, where the most efficient find is used and returned immediately.
Insert and remove both take inital performance hits from sharding because of the
extra calculations taken to find the servers to insert on. However, once more
clients are added they start to speed up again because there are less collisions
and more can happen simeltaneously.

In terms of the N = 5 system, the difference between this and the N = 1 system is
essentially the same as the differences between the N = 3 and N = 1 system like I
just described above. The interesting comparison here is with the N = 3 system,
as it is continuing to add more concurrency and replication at the same time.

As we would expect, the inserts and removes start off slower than the N = 3 case,
because there is more replication happening and therefore three RPCs must be made
for one operation, which is greater than the two happening in the system before.
As we get into the 4-5 client range, these operations catch up to their N = 3
counterparts, which is the point where there is enough extra work happening
to meet the full capacity of all the servers. As we move into the 6 - 7 client
range, these ops start to plateu. 

Probably the most important observation here is just how large the benefit to
lookup and scan having more servers has. Because lookup isn't slowed down by
replication and returns the first calue it gets back, adding more servers just
makes it even more efficient. Scan does have to look through more values with
extra replication, but having multiple clients makes it much faster becuase
multiple different servers can be scanned concurrently. 

The bottom line is that in general, having more servers will allow for each client
to take less of a performance hit on each operation. On the flipside, insert, scan,
and delete take longer to complete as replication is added to the system because
multiple requests are being sent per operation. Lookup is a special case where
even adding replication doesn't slow it down, so it in particular benefits
heavily from a system with a distributed server.